var documenterSearchIndex = {"docs":
[{"location":"#AllometricModels","page":"Home","title":"AllometricModels","text":"Documentation for AllometricModels.\n\n","category":"section"},{"location":"#AllometricModels.β0","page":"Home","title":"AllometricModels.β0","text":"const β0 = InterceptTerm{true}()\n\nRepresents an intercept term for linear models.\n\n\n\n\n\n","category":"constant"},{"location":"#AllometricModels.AllometricModel","page":"Home","title":"AllometricModels.AllometricModel","text":"struct AllometricModel{F<:FormulaTerm,N<:NamedTuple,T<:Float64,B<:Bool}\n\nRepresents a fitted linear model.\n\nFields\n\nformula::F: The formula used to specify the relationship between dependent and independent variables.\ndata::N: The data set (e.g., NamedTuple or DataFrame) containing the variables used in the model.\nβ::Array{T,1}: The estimated regression coefficients (a vector).\nresiduals::Array{T,1}: The residuals, representing the difference between observed and predicted values.\nσ²::T: The variance of residuals, indicating the variability of residuals around the fitted values.\nr²::T: The coefficient of determination (R²), measuring the proportion of variance explained by the model.\nadjr²::T: The adjusted R², adjusted for the number of predictors.\nd::T: The Willmott’s index of agreement, indicating how closely the predicted values match the observed values.\nmse::T: The mean squared error, representing the average squared residual.\nrmse::T: The root mean squared error, a measure of the prediction error.\nsyx::T: The standard error of the estimate (Syx), expressed as a percentage of the mean response.\naic::T: The Akaike Information Criterion, used for model comparison.\nbic::T: The Bayesian Information Criterion, penalizing model complexity more heavily than AIC.\nnormality::B: Boolean flag indicating whether residuals follow a normal distribution (true or false).\nsignificance::B: Boolean flag indicating whether all coefficients are statistically significant (true if all p-values < 0.05).\n\n\n\n\n\n","category":"type"},{"location":"#AllometricModels.isnormality-Tuple{AbstractVector{<:Real}}","page":"Home","title":"AllometricModels.isnormality","text":"isnormality(x)\n\nTests if the input vector x (residuals) comes from a Normal distribution. Returns true if the null hypothesis (normality) cannot be rejected (p > 0.05).\n\nImplementation details:\n\nN < 3: Insufficient data (defaults to true).\n3 ≤ N ≤ 5000: Uses Shapiro-Wilk (Gold standard for this range).\nN > 5000: Uses Jarque-Bera (Asymptotic test suitable for large samples).\n\n\n\n\n\n","category":"method"},{"location":"#AllometricModels.predictbiascorrected-Tuple{Vector{<:Real}, NamedTuple, StatsModels.FunctionTerm, Real}","page":"Home","title":"AllometricModels.predictbiascorrected","text":"predictbiascorrected(ẑ, cols, ft, σ²)\n\nCalculates the bias-corrected predictions (ŷ) on the original scale, based on the transformed linear predictor (ẑ). Uses the Log-Normal correction for logarithmic models and the Second-Order Delta Method for inverse models.\n\nThis function creates and returns a new vector ŷ, leaving ẑ unchanged.\n\n\n\n\n\n","category":"method"},{"location":"#StatsAPI.predict-Tuple{AllometricModel}","page":"Home","title":"StatsAPI.predict","text":"predict(model::AllometricModel)\n\nGenerates predictions from a regression model on the original scale of the dependent variable.\n\nThis function automatically handles the back-transformation of the dependent variable (y) if it was transformed during model fitting (e.g., log(y), 1/y). Crucially, it applies statistical bias correction to account for the non-linear transformation of the error term (Jensen's Inequality), ensuring unbiased estimates on the original scale.\n\nCorrection Strategies\n\nThe function detects the transformation used and applies the appropriate correction:\n\n1. Log-Normal Correction (Exact): For logarithmic transformations (log(y)), it applies the analytical solution for the mean of a log-normal distribution (often called the Meyer or Baskerville correction): Ey = exp(hatz + sigma^22)\n\n2. Delta Method Correction (Approximate): For other non-linear transformations (e.g., 1/y, 1/√y), it employs the Second-Order Delta Method. This uses a truncated Taylor Series expansion to adjust for the curvature of the inverse function: Ey approx g(hatz) + frac12sigma^2 g(hatz)\n\nWhere:\n\nhatz is the prediction on the transformed scale (linear predictor).\ng(cdot) is the inverse transformation function.\nsigma^2 is the residual mean squared error (MSE) of the model.\n\nParameters\n\nmodel: An AllometricModel object containing the fitted regression parameters, formula, and residual variance.\n\nReturns\n\nVector{Float64}: The predicted values on the original scale of y, adjusted for transformations and corrected for bias.\n\nReferences\n\nBaskerville, G. L. (1972). Use of logarithmic regression in the estimation of plant biomass. Canadian Journal of Forest Research.\nCarroll, R. J., & Ruppert, D. (1988). Transformation and Weighting in Regression. Chapman and Hall.\nMiller, D. M. (1984). Reducing transformation bias in curve fitting. The American Statistician.\n\nExamples\n\nSingle Model Prediction:\nypred = predict(model)\n\n\n\n\n\n","category":"method"}]
}
