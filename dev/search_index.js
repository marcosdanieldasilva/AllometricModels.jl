var documenterSearchIndex = {"docs":
[{"location":"#AllometricModels","page":"Home","title":"AllometricModels","text":"Documentation for AllometricModels.\n\n","category":"section"},{"location":"#AllometricModels.β0","page":"Home","title":"AllometricModels.β0","text":"const β0 = InterceptTerm{true}()\n\nRepresents an intercept term for linear models.\n\n\n\n\n\n","category":"constant"},{"location":"#AllometricModels.AllometricModel","page":"Home","title":"AllometricModels.AllometricModel","text":"struct AllometricModel{F<:FormulaTerm,N<:NamedTuple,T<:Float64,B<:Bool}\n\nRepresents a fitted linear model.\n\nFields\n\nformula::F: The formula used to specify the relationship between dependent and independent variables.\ndata::N: The data set (e.g., NamedTuple or DataFrame) containing the variables used in the model.\nβ::Array{T,1}: The estimated regression coefficients (a vector).\nresiduals::Array{T,1}: The residuals, representing the difference between observed and predicted values.\nσ²::T: The variance of residuals, indicating the variability of residuals around the fitted values.\nr²::T: The coefficient of determination (R²), measuring the proportion of variance explained by the model.\nadjr²::T: The adjusted R², adjusted for the number of predictors.\nd::T: The Willmott’s index of agreement, indicating how closely the predicted values match the observed values.\nmse::T: The mean squared error, representing the average squared residual.\nrmse::T: The root mean squared error, a measure of the prediction error.\nsyx::T: The standard error of the estimate (Syx), expressed as a percentage of the mean response.\naic::T: The Akaike Information Criterion, used for model comparison.\nbic::T: The Bayesian Information Criterion, penalizing model complexity more heavily than AIC.\nnormality::B: Boolean flag indicating whether residuals follow a normal distribution (true or false).\nsignificance::B: Boolean flag indicating whether all coefficients are statistically significant (true if all p-values < 0.05).\n\n\n\n\n\n","category":"type"},{"location":"#AllometricModels.LinearModel-Union{Tuple{B}, Tuple{T}, Tuple{N}, Tuple{F}, Tuple{F, N, Vector{T}, Vector{T}, T, T, T, T, T, T, T, T, T, T, B, B}} where {F, N, T, B}","page":"Home","title":"AllometricModels.LinearModel","text":"LinearModel(formula::F, data::N, β::Array{T,1}, residuals::Array{T,1}, σ²::T, r²::T, adjr²::T, d::T, mse::T, rmse::T, mae::T, syx::T, aic::T, bic::T, normality::B, significance::B)\n\nCreates a new `LinearModel` instance.\n\nArguments\n\nformula::F: The formula used to specify the relationship between dependent and independent variables.\ndata::N: The data set (e.g., NamedTuple or DataFrame) containing the variables used in the model.\nβ::Array{T,1}: The estimated regression coefficients (a vector).\nresiduals::Array{T,1}: The residuals, representing the difference between observed and predicted values.\nσ²::T: The variance of residuals, indicating the variability of residuals around the fitted values.\nr²::T: The coefficient of determination (R²), measuring the proportion of variance explained by the model.\nadjr²::T: The adjusted R², adjusted for the number of predictors.\nd::T: The Willmott’s index of agreement, indicating how closely the predicted values match the observed values.\nmse::T: The mean squared error, representing the average squared residual.\nrmse::T: The root mean squared error, a measure of the prediction error.\nmse::T: The mean absolute error as the average absolute residual value.\nsyx::T: The standard error of the estimate (Syx), expressed as a percentage of the mean response.\naic::T: The Akaike Information Criterion, used for model comparison.\nbic::T: The Bayesian Information Criterion, penalizing model complexity more heavily than AIC.\nnormality::B: Boolean flag indicating whether residuals follow a normal distribution (true or false).\nsignificance::B: Boolean flag indicating whether all coefficients are statistically significant (true if all p-values < 0.05).\n\nReturns\n\nLinearModel{F, N, T, B}: A new fitted linear model instance, encapsulating all model parameters and metrics.\n\nType Parameters\n\nF: The type of the formula term (e.g., FormulaTerm).\nN: The type of the data structure (e.g., NamedTuple).\nT: The numeric type used for calculations (e.g., Float64).\nB: The boolean type (Bool).\n\n\n\n\n\n","category":"method"},{"location":"#AllometricModels.predict-Tuple{AllometricModel}","page":"Home","title":"AllometricModels.predict","text":"predict(model::AllometricModel)\n\nThe predict function family provides a versatile way to generate predictions from regression models,    supporting both individual and grouped models. It handles predictions on the original scale even if the    dependent variable (y) has been transformed (e.g., log(y)), ensuring that any transformations     applied during model fitting are correctly reversed, including the application of Meyer correction     factors for logarithmic transformations.\n\nParameters:\n\nmodel:    The regression model(s) to be evaluated and compared. This parameter can accept:\nAllometricModel: A single linear regression model.\n\nReturns:\n\nVector{<:Real} or Vector{Union{Missing, <:Real}}: The predicted values on the original scale of y, adjusted for any transformations and corrected using the Meyer factor for logarithmic transformations.\n\nKey Features:\n\nHandles Transformed Dependent Variables: If the dependent variable was transformed (e.g., using log transformations), the function correctly inverts the transformation to return predictions on the original scale.\nApplies Meyer Correction Factor: For models using logarithmic transformations, the Meyer correction factor is applied to the predictions to correct for the bias introduced by the log transformation.\n\nExamples:\n\nSingle Model Prediction:\ny_pred = predict(model)\n\n\n\n\n\n","category":"method"},{"location":"#AllometricModels.predictBiasCorrected-Tuple{NamedTuple, StatsModels.FunctionTerm, Vector{<:Real}, Real}","page":"Home","title":"AllometricModels.predictBiasCorrected","text":"predictBiasCorrected(cols, ft, ẑ, σ²)\n\nComputes bias-corrected predictions on the original scale, accounting for the non-linear transformation of the error term (Jensen's Inequality).\n\nCorrection Strategies\n\nLog-Normal (Exact): For logarithmic transformations, applies the analytical solution for the mean of a log-normal distribution: Ey = exp(hatz + sigma^22)\n\nDelta Method (Approximate): For other non-linear transformations (e.g., inverse, inverse square root), employs the Second-Order Delta Method. This uses a truncated Taylor Series expansion to adjust for the curvature of the inverse function: Ey approx g(hatz) + frac12sigma^2 g(hatz)\n\nArguments\n\ncols: NamedTuple containing original data (required for interaction terms).\nft: The FunctionTerm from the model formula.\nẑ: Vector of predictions on the transformed scale (linear predictor).\nσ²: The residual mean squared error (MSE) of the model.\n\nReferences\n\nBaskerville, G. L. (1972). Use of logarithmic regression in the estimation of plant biomass. Canadian Journal of Forest Research.\nCarroll, R. J., & Ruppert, D. (1988). Transformation and Weighting in Regression. Chapman and Hall.\n\n\n\n\n\n","category":"method"}]
}
